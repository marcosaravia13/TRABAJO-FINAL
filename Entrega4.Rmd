---
title: "¿Qué explica la mortalidad infantil?"
author: "Marco Saravia"
date: "24 de junio de 2022"
output:
  rmdformats::readthedown:
    code_folding: show
  html_document:
    df_print: paged
  toc_depth: 5
  toc: yes
  lightbox: yes
  toc_float:
    collapsed: no
    smooth_scrool: yes
  thumbnails: yes
  self_contained: yes
---

```{r setup, include=FALSE, message=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**REPOSITORIO GITHUB: https://github.com/marcosaravia13/TRABAJO-FINAL.git**

```{r message=FALSE, echo=FALSE, include=FALSE}
library(rio)
library(Rmisc)
library (stargazer)
library(moments)
library(DescTools)
library(BBmisc)
library(cluster)
library(factoextra)
library(qpcR)
library(polycor)
library(ggcorrplot)
library(magrittr)
library(psych)
library(matrixcalc)
library(lavaan)

link="https://github.com/marcosaravia13/TRABAJO-FINAL/blob/d3b2c2e988e3e9c766725528493b17971bb66aff/DATA1.xlsx?raw=true"
data=import(link)
```

```{r message=FALSE, echo=FALSE, include=FALSE}
#Observamos la esstructura de las variables a emplear dentro de la data: 
str(data)
```
```{r message=FALSE, echo=FALSE, include=FALSE}
#Configuración de la data
#Se transforman las variables correspondientes a numéricas: 
data$handwashing=as.numeric(data$handwashing)
data$mortality_rate=as.numeric(data$mortality_rate)
data$incidence_tuberculosis=as.numeric(data$incidence_tuberculosis)

#Se elimninan los variables perdidos de la data:
data = data[complete.cases(data$mortality_rate),]
data = data[complete.cases(data$handwashing),]
data = data[complete.cases(data$incidence_tuberculosis),]
```

# ANÁLISIS DE REGRESIÓN

Para el proceso de análisis de regresión, se tomó en consideración realziar tres diferentes modelos que invlocuren a las tres variables empleadas en el presente trabajo: Mortalidad infantil, número de habitantes con acceso al lavado de manos y la incidendia de tuberculosis por país. Para el análisis de regresión se han tomado en cuenta dos modelos de regresión simple que evalúe la relación explicativa entre las variables en pares y una regresión múltiple que tome en cuenta la totalidad de las variables. Asimismo, para los tres casos se ha tomado en cuenta como variable independiente a la tasa de mortalidad a nivel mundial. 

El primer modelo de regresión simple evalúa la relaciónb entre la tasa de mortalidad y el acceso de las personas al servicio de lavado de manos. En el modelo encotnraremos que el p-value es menor a 0.05, por lo que se puede decir que no se puede negar que el modelo sea falso. Por lo tanto, no se rechaza la viabilidad del mismo y hay una relación de dependencia. Del mismo modo, se debe considerar que el R2 del modelo es de 0.5622.

En el segundo modelo, el cual toma en cuenta la relación entre la tasa de mortalidad y la incidencia de tuberculoisis, se observa que el p-value resulta ser, del mismo mod, meor a 0.05, por lo que se puede decir que no se puede negar que el modelo sea falso. Por lo tanto, no se rechaza la viabilidad del mismo y hay una relación de dependencia. Del mismo modo, se debe considerar que el R2 del modelo es de 0.1884. Sin embargo, es por ello que este modelo resulta ser menos explicativo que el primero. 

No obstante, cuando se observa el tercer modelo, el cual involucra la totalidad de las variables, veremos que el pvalue es menor a 0.05 lo que impide rechazar la viabilidad del modelo, al mismo tiempo que muestra un rsquared maypr a los demás presentados (0.6) de forma positiva. Es decir, la relación del modelo es direta. Ello, además, se comprueba al observar la tabla anova.


```{r message=FALSE, echo=FALSE, include=FALSE}
Modelo1=formula(data$mortality_rate~data$handwashing)
reg1=lm(Modelo1,data=data)
modelo2=formula(data$mortality_rate~data$incidence_tuberculosis)
reg2=lm(modelo2,data=data)
```


**TERCER MODELO: MODELO DE REGRESIÓN MÚLTIPLE**

```{r message=FALSE, echo=FALSE, include=FALSE}
modelo3=formula(data$mortality_rate~data$handwashing+data$incidence_tuberculosis)
reg3=lm(modelo3,data=data)
summary(reg3)
```

```{r message=FALSE, echo=FALSE}
stargazer(reg3,type = "text",intercept.bottom = FALSE)
```


#### COMPARACIÓN DE LOS MODELOS

A partir de la información presentada, se evidencia que el mejor de los modelos presentados es el modelo de regresión MÚLTIPLE que involucra todas las variables. 

```{r message=FALSE, echo=FALSE}
stargazer(reg1,reg2,reg3, type = "text")
```

```{r}
tanova=anova(reg1, reg2, reg3)
stargazer(tanova,type = "text", summary = F, title = "Table de Análisis")
```

** Los modelos de regresión simple (1ro y 2do) se encuentran en anexos. 
** Los gráficos que permiten comprobar el modelo de regresión presentado se encuentran en la lista de anexos. 


# ANÁLISIS DE CONGLOMERADOS

Para poder realizar el análisis de conglomerados, así como el análisis factorial, se ha trabajado con una base de datos externa que ha sido unida a la ya existente. 

```{r message=FALSE, echo=FALSE, include=FALSE}
link2="https://raw.githubusercontent.com/marcosaravia13/TRABAJO-FINAL/main/data_claus.csv"
data_clus=import(link2)
str(data_clus)
```

## PREPARACIÓN DE LA DATA PARA SER CLUSTERIZADA

#### DISTRIBUCIÓN DE LAS VARIABLES 

```{r message=FALSE, echo=FALSE, include=FALSE}
boxplot(data_clus[,-1])
```

Es evidente que por la propia naturaleza de la investigación, la distribución de las variables es independiente en cada una pues el insicador de medición en cada una de ellas ha sido trabajado de una manera diferente, por lo que es conveniente estandarizar las variables y realizar una mejor clusterización. 
Una vez que se han estandarizado, es posible trbajar la clusterización, pues se ha determinado un valor estánjdar de medición para todas las variables. Es importante notar, al mismo tiempo que, a partir de una examinación de las correlaciones dentro de la data presenta, se hace evidente la necesidad se establecer una monotonía en las variables, sin embargo, esta solo se realiza a la de handwashing, en tanto es mpas conveniente por los posteriores efectos del proceso. 

** Cuadro de correlaciones en anexos. 

```{r message=FALSE, echo=FALSE}
boxplot(normalize(data_clus[,-1],method='standardize'))
data_clus[,-1]=normalize(data_clus[,-1],method='standardize')
```
 
```{r message=FALSE, echo=FALSE, include=FALSE}
cor(data_clus[,-1])
data_clus$handwashing=-1*data_clus$handwashing
```

```{r message=FALSE, echo=FALSE, include=FALSE}
#POR LA FORMA EN QUE SE LLEVA LA CUSLTERIZACIÓN, ES NECESARIO ELIMINAR LA COLUMNA QUE LLEVA EL NOMBRE DE LOS PAÍSES, PUES SOLO SE DEB TRBAJAR CON LAS VAIRABLES NUMÉRICAS. POR ELLO, ESTA VARIABLE SERÁ AHORA TOMADA EN CUENTA COMO LA COLUMNA DE ROWS. 

row.names(data_clus)=data_clus$country
data_clus=data_clus[,-1]
```

## CLUSTERIZACIÓN

Para poder realizar el procesod e clusterización es necesario, dentro de un marco confirmativo, tomar en cuenta las siluetas presentadas a partir de los gráficos, los cuales muestran como  mjeor opción que la clusterización sería mejor reaziada a aprtir de 2 clusters. A su vez, se evidenció que a pesar de que la diferencia entre los modelos no sea significativa, pues fue de 0.1, el modelo DIANA no presenta elemntos no clusterizables, a diferencia de los modelos de PAM Y AGNES, que presentaban 2 elementos y 1 respectivamente. De acuerdo a ello, se observa que la mejor op´ción a utilizar corresponde a la clusterización por jerarquía divisible, es decir el método DIANA. 

```{r message=FALSE, echo=FALSE, include=FALSE}
g.dist = daisy(data_clus, metric="gower")
```

```{r message=FALSE, echo=FALSE, include=FALSE}
fviz_nbclust(data_clus, hcut,diss=g.dist,method ="gap_stat",k.max =10,verbose =F,hc_func ="diana")
```

```{r message=FALSE, echo=FALSE, include=FALSE}
###pam
set.seed(123)
grupos=2
res.pam=pam(g.dist,k = grupos,cluster.only =F)
data_clus$pam=res.pam$cluster

###agnes
res.agnes<- hcut(g.dist, grupos,hc_func='agnes',hc_method ="ward.D")
data_clus$agnes=res.agnes$cluster

### diana
res.diana <- hcut(g.dist, k = grupos,hc_func='diana')
data_clus$diana=res.diana$cluster
```

```{r message=FALSE, echo=FALSE}
fviz_silhouette(res.diana)
```

En ese sentido, se observa en la siguiente proyección, los dos clusters seleccionados. Y, posteriormente, se observa el dendograma que permite visuizar las distnacias enntre los elementos de ambos clsuters. 

```{r message=FALSE, echo=FALSE}
proyeccion = cmdscale(g.dist, k=2,add =T)
data_clus$dim1 <- proyeccion$points[,1]
data_clus$dim2 <- proyeccion$points[,2]
base= ggplot(data_clus,aes(x=dim1, y=dim2,label=row.names(data_clus)))
base + geom_text(size=2, aes(color=as.factor(diana))) + labs(title ="DIANA")
```

```{r message=FALSE, echo=FALSE}
fviz_dend(res.diana, cex =0.7, horiz =T)
```

# ANÁLISIS FACTORIAL

## ANÁLISIS FACTORIAL EXPLORATORIO

```{r message=FALSE, echo=FALSE, include=FALSE}
data_af=import(link2)
row.names(data_af)=data_af$country
data_af=data_af[ ,-1]
```

### EXPLORACIÓN DE CORRELACIÓN
```{r message=FALSE, echo=FALSE}
corMatrix=polycor::hetcor(data_af)$correlations
ggcorrplot(corMatrix)
```

```{r r message=FALSE, echo=FALSE, include=FALSE}
psych::KMO(corMatrix ) 
```
#### MATRIZ DE IDENTIDAD
```{r }
cortest.bartlett(corMatrix,n=nrow(data_af))$p.value>0.05
```
#### MATRIZ SINGULAR
```{r }
is.singular.matrix(corMatrix)
```

Se determina que, pro los datos dados, es posibel determinar un solo factor o concepto. 
```{r}
fa.parallel(data_af,fm = 'ML', fa = 'fa',correct = T)
```

```{r mesage=FALSE, echo=FALSE mesage=FALSE, echo=FALSE}
#install.packages("GPArotation")
library(GPArotation)
resfa <- fa(data_af,
            nfactors = 1,
            cor = 'mixed',
            rotate = "varimax",
            fm="minres")
print(resfa$loadings)
```
```{r mesage=FALSE, echo=FALSE, include=FALSE}
print(resfa$loadings,cutoff = 0.5)
```

### RESULTADO VISUAL
```{r mesage=FALSE, echo=FALSE}
fa.diagram(resfa)
```
### APORTE DE LAS VARIABLES

```{r mesage=FALSE, echo=FALSE}
sort(resfa$communality)
```

```{r mesage=FALSE, echo=FALSE}
sort(resfa$complexity)
```

```{r mesage=FALSE, echo=FALSE, include=FALSE}
as.data.frame(resfa$scores)%>%head()
```


## ANÁLISIS FACTORIAL COMNFIRMATORIO

```{r mesage=FALSE, echo=FALSE, include=FALSE}
model <- ' CONCEPTO  =~ mortality_rate + handwashing + incidence_tuberculosis + life_expectancy_at_birth + water_services + financial_flows + children_anemia'
```

```{r mesage=FALSE, echo=FALSE, include=FALSE}
data_norm=as.data.frame(scale(data_af))
```

```{r mesage=FALSE, echo=FALSE, include=FALSE}
cfa_fit <- cfa(model, data_norm, 
           std.lv=TRUE,  
           missing="fiml")
```

```{r mesage=FALSE, echo=FALSE, include=FALSE}
allParamCFA=parameterEstimates(cfa_fit,standardized = T)
allFitCFA=as.list(fitMeasures(cfa_fit))
```

Se observa la relación de las variabels frente al concepto:
```{r}
allParamCFA[allParamCFA$op=="=~",]
```

### PRUEBAS DE CONFIRMACIÓN

CHISQUARE

```{r}
allFitCFA[c("chisq", "df", "pvalue")] # pvalue>0.05
```

TUCKER LEWI
```{r}
allFitCFA$tli # > 0.90
```

RAIZ DEL ERROR
```{r}
allFitCFA[c('rmsea.ci.lower','rmsea' ,'rmsea.ci.upper')] # 0.05 en el Int de Conf?
```

```{r}
scorescfa=normalize(lavPredict(cfa_fit),
                    method = "range", 
                    margin=2, # by column
                    range = c(0, 10))
```


# ANEXOS

#### MODELOS DE REGRESIÓN DEL 1ER Y 2DO MODELO:

PRIMER MODELO 
```{r message=FALSE, echo=FALSE}
Modelo1=formula(data$mortality_rate~data$handwashing)
reg1=lm(Modelo1,data=data)
summary(reg1)
```

SEGUNDEO MODELO
```{r message=FALSE, echo=FALSE}
modelo2=formula(data$mortality_rate~data$incidence_tuberculosis)
reg2=lm(modelo2,data=data)
summary(reg2)
```


#### 1.GRÁFICOS PARA LA COMPROBACIÓN DEL MODELO CREADO:

#### 1.1.LINEALIDAD

```{r echo=FALSE, message=FALSE}
plot(reg3, 1)
```

#### 1.2.HOMOCEDASTICIDAD
```{r message=FALSE, echo=FALSE}
plot(reg3, 3)
```

#### 1.3.NORMALIDAD DE LOS RESIDUOS
```{r message=FALSE, echo=FALSE}
plot(reg3,2)
```

```{r message=FALSE, echo=FALSE}
shapiro.test(reg3$residuals)
```

#### 1.4.CASOS INFLUYENTES
```{r message=FALSE, echo=FALSE}
plot(reg3, 5)
```

#### 1.5. MULTICOLINEALIDAD

```{r}
VIF(reg3)
```

#### 2.Correlaciones
```{r message=FALSE, echo=FALSE}
cor(data_clus)
```

#### 3. SELECCIÓN DE CULSTERIZACIÓN POR PAM, AGNES Y  DIANA, RESPEDCTIVAMENTE:

```{r message=FALSE, echo=FALSE}
fviz_nbclust(data_clus, pam,diss=g.dist,method ="gap_stat",k.max =10,verbose =F)
fviz_nbclust(data_clus, hcut,diss=g.dist,method ="gap_stat",k.max =10,verbose =F,hc_func ="agnes")
fviz_nbclust(data_clus, hcut,diss=g.dist,method ="gap_stat",k.max =10,verbose =F,hc_func ="diana")
```

Siluetas de los tres métodos correspondientes:

```{r message=FALSE, echo=FALSE}
fviz_silhouette(res.pam)
fviz_silhouette(res.agnes)
fviz_silhouette(res.diana)
```

##### 4.DATOS MAL CLAUSTERIZADOS
```{r message=FALSE, echo=FALSE}
silPAM=data.frame(res.pam$silinfo$widths)
silPAM$country=row.names(silPAM)
poorPAM=silPAM[silPAM$sil_width<0,'country']%>%sort()

silAGNES=data.frame(res.agnes$silinfo$widths)
silAGNES$country=row.names(silAGNES)
poorAGNES=silAGNES[silAGNES$sil_width<0,'country']%>%sort()

silDIANA=data.frame(res.diana$silinfo$widths)
silDIANA$country=row.names(silDIANA)
poorDIANA=silDIANA[silDIANA$sil_width<0,'country']%>%sort()

mal_Clus=as.data.frame(qpcR:::cbind.na(poorPAM, poorAGNES,poorDIANA))
mal_Clus
```



